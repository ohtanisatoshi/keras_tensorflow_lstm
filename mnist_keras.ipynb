{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.initializers import TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800 12800\n",
      "3200 3200\n",
      "4000 4000\n"
     ]
    }
   ],
   "source": [
    "n = len(mnist.data)\n",
    "N = 20000\n",
    "indices = np.random.permutation(range(n))[:N]\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]\n",
    "\n",
    "# 正規化するために最大値255で割る（0〜1の範囲となる)\n",
    "X = X / 255.0\n",
    "# 平均を0とする\n",
    "X = X - X.mean(axis=1).reshape(len(X), 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, train_size=0.8)\n",
    "print(len(X_train), len(Y_train))\n",
    "print(len(X_validation), len(Y_validation))\n",
    "print(len(X_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return np.random.normal(scale=0.1, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = len(X[0]) # 784\n",
    "n_hidden = [200, 200, 200]\n",
    "n_out = len(Y[0]) # 10\n",
    "dropout_rate = 0.5\n",
    "model = Sequential()\n",
    "\n",
    "for i, h in enumerate(n_hidden):\n",
    "    if i == 0:\n",
    "        # model.add(Dense(h, input_dim=n_in, kernel_initializer=weight_variable))\n",
    "        model.add(Dense(h, input_dim=n_in, kernel_initializer='he_normal'))\n",
    "    else:\n",
    "        model.add(Dense(h, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(n_out, kernel_initializer=weight_variable))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/200\n",
      "12800/12800 [==============================] - 3s - loss: 2.3193 - acc: 0.1540 - val_loss: 2.0405 - val_acc: 0.5762\n",
      "Epoch 2/200\n",
      "12800/12800 [==============================] - 2s - loss: 2.0792 - acc: 0.2608 - val_loss: 1.7564 - val_acc: 0.6425\n",
      "Epoch 3/200\n",
      "12800/12800 [==============================] - 1s - loss: 1.8394 - acc: 0.3651 - val_loss: 1.4008 - val_acc: 0.6909\n",
      "Epoch 4/200\n",
      "12800/12800 [==============================] - 2s - loss: 1.5976 - acc: 0.4531 - val_loss: 1.1022 - val_acc: 0.7406\n",
      "Epoch 5/200\n",
      "12800/12800 [==============================] - 1s - loss: 1.4012 - acc: 0.5150 - val_loss: 0.9039 - val_acc: 0.7734\n",
      "Epoch 6/200\n",
      "12800/12800 [==============================] - 1s - loss: 1.2485 - acc: 0.5670 - val_loss: 0.7712 - val_acc: 0.8022\n",
      "Epoch 7/200\n",
      "12800/12800 [==============================] - 1s - loss: 1.1254 - acc: 0.6166 - val_loss: 0.6751 - val_acc: 0.8238\n",
      "Epoch 8/200\n",
      "12800/12800 [==============================] - 2s - loss: 1.0424 - acc: 0.6445 - val_loss: 0.6112 - val_acc: 0.8434\n",
      "Epoch 9/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.9706 - acc: 0.6724 - val_loss: 0.5601 - val_acc: 0.8503\n",
      "Epoch 10/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.9030 - acc: 0.6971 - val_loss: 0.5185 - val_acc: 0.8650\n",
      "Epoch 11/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.8583 - acc: 0.7165 - val_loss: 0.4886 - val_acc: 0.8691\n",
      "Epoch 12/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.8050 - acc: 0.7378 - val_loss: 0.4585 - val_acc: 0.8747\n",
      "Epoch 13/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.7794 - acc: 0.7513 - val_loss: 0.4427 - val_acc: 0.8800\n",
      "Epoch 14/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.7356 - acc: 0.7669 - val_loss: 0.4204 - val_acc: 0.8828\n",
      "Epoch 15/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.7222 - acc: 0.7690 - val_loss: 0.4038 - val_acc: 0.8878\n",
      "Epoch 16/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.6787 - acc: 0.7862 - val_loss: 0.3879 - val_acc: 0.8875\n",
      "Epoch 17/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.6493 - acc: 0.7952 - val_loss: 0.3725 - val_acc: 0.8903\n",
      "Epoch 18/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.6410 - acc: 0.7984 - val_loss: 0.3646 - val_acc: 0.8922\n",
      "Epoch 19/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.6205 - acc: 0.8089 - val_loss: 0.3555 - val_acc: 0.8963\n",
      "Epoch 20/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.5889 - acc: 0.8195 - val_loss: 0.3450 - val_acc: 0.8988\n",
      "Epoch 21/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.5837 - acc: 0.8231 - val_loss: 0.3368 - val_acc: 0.9031\n",
      "Epoch 22/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.5658 - acc: 0.8230 - val_loss: 0.3291 - val_acc: 0.9041\n",
      "Epoch 23/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.5514 - acc: 0.8351 - val_loss: 0.3208 - val_acc: 0.9053\n",
      "Epoch 24/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.5436 - acc: 0.8345 - val_loss: 0.3165 - val_acc: 0.9059\n",
      "Epoch 25/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.5310 - acc: 0.8402 - val_loss: 0.3085 - val_acc: 0.9100\n",
      "Epoch 26/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.5143 - acc: 0.8455 - val_loss: 0.3054 - val_acc: 0.9100\n",
      "Epoch 27/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4978 - acc: 0.8541 - val_loss: 0.2982 - val_acc: 0.9116\n",
      "Epoch 28/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.5021 - acc: 0.8492 - val_loss: 0.2930 - val_acc: 0.9144\n",
      "Epoch 29/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4821 - acc: 0.8585 - val_loss: 0.2890 - val_acc: 0.9147\n",
      "Epoch 30/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4726 - acc: 0.8588 - val_loss: 0.2866 - val_acc: 0.9153\n",
      "Epoch 31/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4658 - acc: 0.8617 - val_loss: 0.2810 - val_acc: 0.9188\n",
      "Epoch 32/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4574 - acc: 0.8632 - val_loss: 0.2782 - val_acc: 0.9181\n",
      "Epoch 33/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.4417 - acc: 0.8679 - val_loss: 0.2745 - val_acc: 0.9194\n",
      "Epoch 34/200\n",
      "12800/12800 [==============================] - 1s - loss: 0.4399 - acc: 0.8688 - val_loss: 0.2696 - val_acc: 0.9228\n",
      "Epoch 35/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4397 - acc: 0.8745 - val_loss: 0.2678 - val_acc: 0.9231\n",
      "Epoch 36/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4326 - acc: 0.8673 - val_loss: 0.2642 - val_acc: 0.9225\n",
      "Epoch 37/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4174 - acc: 0.8766 - val_loss: 0.2603 - val_acc: 0.9241\n",
      "Epoch 38/200\n",
      "12800/12800 [==============================] - 2s - loss: 0.4109 - acc: 0.8799 - val_loss: 0.2583 - val_acc: 0.9231\n",
      "Epoch 39/200\n",
      "12200/12800 [===========================>..] - ETA: 0s - loss: 0.3979 - acc: 0.8817"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-e4d058d884e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 100\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840/4000 [===========================>..] - ETA: 0s[0.16519954389613123, 0.95474999999999999]\n"
     ]
    }
   ],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL7uto3sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120ad1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), val_acc, label='acc', color='black')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
